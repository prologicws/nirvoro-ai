{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0157a0e9-53e6-47c1-84ab-091c673fb243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dibyendu/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/dibyendu/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <F6236B89-E4CA-3330-B665-E463D537EAF3> /Users/dibyendu/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <A51C8C05-245A-3989-8D3C-9A6704422CA5> /Users/dibyendu/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from pymongo import MongoClient\n",
    "from transformers import pipeline\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193016cd-caaf-45f6-b6ab-61ab071a05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB Setup\n",
    "#client = MongoClient('mongodb://localhost:27017/')  # Update with your MongoDB connection URI\n",
    "mongo_uri = os.getenv('MONGO_URI')  # Load from environment variables\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client['news_database']\n",
    "collection = db['news_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f952323a-33ef-4249-ad71-185e267cc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use explicit model names and enable GPU if available\n",
    "summarizer = pipeline(\n",
    "    'summarization', \n",
    "    model='sshleifer/distilbart-cnn-12-6', \n",
    "    revision='a4f8f3e',\n",
    "    device=0  # Set to 0 for GPU, -1 for CPU\n",
    ")\n",
    "\n",
    "sentiment_analyzer = pipeline(\n",
    "    'sentiment-analysis', \n",
    "    model='distilbert-base-uncased-finetuned-sst-2-english', \n",
    "    revision='714eb0f',\n",
    "    device=0  # Set to 0 for GPU, -1 for CPU\n",
    ")\n",
    "\n",
    "vectorizer = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7664351d-ef4f-4ec5-9a5f-104a8109fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')  # Runs Chrome in headless mode\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    service = Service('/opt/homebrew/bin/chromedriver')  # Update this path if necessary\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f364fd5-fd2a-4c43-ab41-194608a2b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_bias_scores():\n",
    "    \"\"\"\n",
    "    Generate random scores for left, center, and right ensuring their sum is 100.\n",
    "    \"\"\"\n",
    "    left = random.randint(0, 100)\n",
    "    center = random.randint(0, 100 - left)\n",
    "    right = 100 - (left + center)\n",
    "    return {\"left\": left, \"center\": center, \"right\": right}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a066046-cf45-4101-b80b-1652c2992f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_summarize_text(text, max_len=50, min_len=20):\n",
    "    \"\"\"\n",
    "    Clean sensationalism and summarize the input text (title or description).\n",
    "    \"\"\"\n",
    "    # Summarize the input text (if needed)\n",
    "    summary = summarizer(text, max_length=max_len, min_length=min_len, do_sample=False)[0]['summary_text']\n",
    "    \n",
    "    # Bolden important points in the summary\n",
    "    cleaned_summary = bolden_important_points(summary)\n",
    "    \n",
    "    return cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc8012d-4b77-4f97-9253-ea39c45f8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all articles from the collection\n",
    "#articles = []\n",
    "#articles = list(collection.find())\n",
    "#mark_and_save_duplicate_articles();\n",
    "\n",
    "def clean_sensationalism(article_text):\n",
    "    \"\"\"\n",
    "    Cleans sensationalism by detecting overly emotional or sensational language \n",
    "    and rephrasing the text to focus on the facts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Break the text into sentences\n",
    "    if not article_text:  # Check if article_text is None or empty\n",
    "        return \"Content not available or cannot be cleaned.\"\n",
    "    \n",
    "    sentences = article_text.split('. ')\n",
    "    factual_sentences = []\n",
    "    #print(f\"Sentences: {sentences}\")\n",
    "\n",
    "    # Analyze each sentence\n",
    "    for sentence in sentences:\n",
    "        sentiment = sentiment_analyzer(sentence)\n",
    "        if sentiment[0]['label'] in ['NEGATIVE', 'POSITIVE'] and sentiment[0]['score'] > 0.7:\n",
    "            # Skip overly emotional sentences or rewrite them\n",
    "            #print(f\"Skipping sensational sentence: {sentence}\")\n",
    "            continue\n",
    "        factual_sentences.append(sentence)\n",
    "\n",
    "    # Join the factual sentences\n",
    "    clean_text = '. '.join(factual_sentences)\n",
    "    \n",
    "    # Use summarization to condense the cleaned text\n",
    "    summary = summarizer(clean_text, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e41a62c-0807-4c82-91b3-2d2c021eb3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_articles(batch_size=10):\n",
    "    driver = setup_driver()  # Initialize the Selenium driver\n",
    "    try:\n",
    "        while True:\n",
    "            # Fetch unprocessed articles in small batches\n",
    "            articles = list(collection.find({\"processed\": 0}).limit(batch_size))\n",
    "            if not articles:\n",
    "                print(\"No more articles to process.\")\n",
    "                break\n",
    "\n",
    "            updates = []\n",
    "            for article in articles:\n",
    "                try:\n",
    "                    # Prepare update data\n",
    "                    update_data = {\"processed\": 1}\n",
    "\n",
    "                    # Extract first image\n",
    "                    if \"images\" in article and isinstance(article[\"images\"], list) and article[\"images\"]:\n",
    "                        update_data[\"image\"] = article[\"images\"][0]\n",
    "\n",
    "                    # Process text fields\n",
    "                    if \"title_or\" in article:\n",
    "                        update_data[\"title\"] = clean_sensationalism(article[\"title_or\"])\n",
    "                    else:\n",
    "                        print(f\"Missing 'title_or' field in article ID: {article['_id']}\")\n",
    "\n",
    "                    if \"description_or\" in article:\n",
    "                        update_data[\"description\"] = clean_sensationalism(article[\"description_or\"])\n",
    "                        update_data[\"subtitle\"] = summarizer(\n",
    "                            article[\"description_or\"], max_length=50, min_length=20, do_sample=False\n",
    "                        )[0][\"summary_text\"]\n",
    "                    else:\n",
    "                        print(f\"Missing 'description_or' field in article ID: {article['_id']}\")\n",
    "\n",
    "                    # Add update operation\n",
    "                    updates.append(\n",
    "                        {\"filter\": {\"_id\": article[\"_id\"]}, \"update\": {\"$set\": update_data}}\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing article ID {article['_id']}: {e}\")\n",
    "\n",
    "            # Perform bulk write for the batch\n",
    "            if updates:\n",
    "                try:\n",
    "                    bulk_operations = [\n",
    "                        {\n",
    "                            \"updateOne\": {\n",
    "                                \"filter\": upd[\"filter\"],\n",
    "                                \"update\": upd[\"update\"]\n",
    "                            }\n",
    "                        }\n",
    "                        for upd in updates\n",
    "                    ]\n",
    "                    result = collection.bulk_write(bulk_operations)\n",
    "                    print(f\"Updated {result.modified_count} articles.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during bulk write: {e}\")\n",
    "            else:\n",
    "                print(\"No articles to update.\")\n",
    "\n",
    "            # Pause briefly to avoid overwhelming resources\n",
    "            time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during processing: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88999085-698e-4a50-8a5d-203362ece5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_article():\n",
    "    driver = setup_driver()  # Initialize the Selenium driver\n",
    "    try:\n",
    "        # Fetch one unprocessed article\n",
    "        article = collection.find_one({\"processed\": 0})\n",
    "        if not article:\n",
    "            print(\"No more articles to process.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            print(f\"Processing article ID: {article['_id']}\")\n",
    "\n",
    "            # Prepare update data\n",
    "            update_data = {\"processed\": 1}\n",
    "\n",
    "            # Extract first image\n",
    "            if \"images\" in article and isinstance(article[\"images\"], list) and article[\"images\"]:\n",
    "                update_data[\"image\"] = article[\"images\"][0]\n",
    "\n",
    "            # Process text fields\n",
    "            if \"title_or\" in article:\n",
    "                update_data[\"title\"] = clean_sensationalism(article[\"title_or\"])\n",
    "            else:\n",
    "                print(f\"Missing 'title_or' field in article ID: {article['_id']}\")\n",
    "\n",
    "            if \"description_or\" in article:\n",
    "                update_data[\"description\"] = clean_sensationalism(article[\"description_or\"])\n",
    "                update_data[\"subtitle\"] = summarizer(\n",
    "                    article[\"description_or\"], max_length=50, min_length=20, do_sample=False\n",
    "                )[0][\"summary_text\"]\n",
    "            else:\n",
    "                print(f\"Missing 'description_or' field in article ID: {article['_id']}\")\n",
    "\n",
    "            # Generate randomized bias scores\n",
    "            bias_scores = randomize_bias_scores()\n",
    "            update_data.update(bias_scores)\n",
    "\n",
    "            # Perform single update\n",
    "            print(f\"Prepared update data: {update_data}\")\n",
    "            result = collection.update_one({\"_id\": article[\"_id\"]}, {\"$set\": update_data})\n",
    "\n",
    "            # Log result\n",
    "            if result.modified_count == 1:\n",
    "                print(f\"Successfully updated article ID: {article['_id']}\")\n",
    "            else:\n",
    "                print(f\"Article ID: {article['_id']} was not updated.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article ID {article['_id']}: {e}\")\n",
    "            raise  # Re-raise the error for visibility\n",
    "    finally:\n",
    "        driver.quit()  # Ensure the Selenium driver is closed\n",
    "\n",
    "# Run the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45d63d-a93f-478e-bfe0-4cb441e6888c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e28987-8857-4e09-b61f-6847ac953951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article ID: 67600d58c3f742fb3373bb18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 100, but your input_length is only 3. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 100, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared update data: {'processed': 1, 'image': 'https://ichef.bbci.co.uk/news/480/cpsprodpb/4e2b/live/228d0c50-bb33-11ef-aff0-072ce821b6ab.jpg.webp', 'title': ' CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots .', 'description': ' Fiji police are said to be investigating the circumstances of the incident . \"There\\'s a real terrifying sense of deja vu,\" Australian minister Jason Clare told the ABC .', 'subtitle': \" Seven foreigners in Fiji sent to hospital for suspected poisoning after drinking pina coladas at a five-star resort's bar . Five are tourists, with one from the US and the rest from Australia, according to local media reports . Some\", 'left': 24, 'center': 5, 'right': 71}\n",
      "Successfully updated article ID: 67600d58c3f742fb3373bb18\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #process_articles(batch_size=10)\n",
    "    process_single_article()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
