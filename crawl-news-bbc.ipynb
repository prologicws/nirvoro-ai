{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954952b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: feedparser in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (6.0.11)\n",
      "Requirement already satisfied: pymongo in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (4.10.1)\n",
      "Requirement already satisfied: rapidfuzz in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: selenium in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (4.25.0)\n",
      "Requirement already satisfied: transformers in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: sgmllib3k in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from feedparser) (1.0.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from pymongo) (2.7.0)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: filelock in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: networkx in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from urllib3<3,>=1.21.1->requests) (1.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/dibyendu/anaconda3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 feedparser pymongo rapidfuzz selenium transformers torch\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import feedparser\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from rapidfuzz import fuzz\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386da59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB Setup\n",
    "client = MongoClient('mongodb://localhost:27017/')  # Update with your MongoDB connection URI\n",
    "db = client['news_database']\n",
    "collection = db['news_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2478417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')  # Runs Chrome in headless mode\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    service = Service('/opt/homebrew/bin/chromedriver')  # Update this path if necessary\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f579a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_relative_time_to_iso(relative_time):\n",
    "    \"\"\"\n",
    "    Convert a relative time string like '21 hours ago' to an ISO timestamp.\n",
    "    \"\"\"\n",
    "    # Get the current time\n",
    "    current_time = datetime.utcnow()\n",
    "\n",
    "    # Use regular expressions to extract time units and values\n",
    "    match = re.match(r\"(\\d+)\\s*(\\w+)\\s*ago\", relative_time)\n",
    "    if not match:\n",
    "        return None  # Return None if the format is not recognized\n",
    "\n",
    "    amount, unit = int(match.group(1)), match.group(2)\n",
    "\n",
    "    # Convert the time unit into a timedelta object\n",
    "    if \"hour\" in unit:\n",
    "        time_delta = timedelta(hours=amount)\n",
    "    elif \"minute\" in unit:\n",
    "        time_delta = timedelta(minutes=amount)\n",
    "    elif \"second\" in unit:\n",
    "        time_delta = timedelta(seconds=amount)\n",
    "    elif \"day\" in unit:\n",
    "        time_delta = timedelta(days=amount)\n",
    "    else:\n",
    "        return None  # If it's a unit we don't handle, return None\n",
    "\n",
    "    # Subtract the timedelta from the current time\n",
    "    calculated_time = current_time - time_delta\n",
    "\n",
    "    # Convert to ISO format\n",
    "    return calculated_time.isoformat() + \"Z\"  # Adding 'Z' to denote UTC time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2a308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch full news content and additional details from the news article page\n",
    "def fetch_full_article_bbc(url, driver):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        #time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Initialize fields\n",
    "        full_text = \"\"\n",
    "        published_time = \"\"\n",
    "        published_time_raw = \"\"\n",
    "        author_name = \"\"\n",
    "        author_designation = \"\"\n",
    "        reporting_location = \"\"\n",
    "        images = []\n",
    "\n",
    "        # Extract the article content\n",
    "        article = soup.find('article')\n",
    "        if article:\n",
    "            # Extract paragraphs\n",
    "            paragraphs = article.find_all('p')\n",
    "            full_text = ' '.join([p.get_text() for p in paragraphs])\n",
    "            #print(f\"Full text: {full_text}\")\n",
    "\n",
    "            # Extract published time\n",
    "            time_tag = article.find('time')\n",
    "            if time_tag:\n",
    "                published_time_raw = time_tag.get_text()                \n",
    "                print(f\"Time: {published_time_raw}\")\n",
    "                published_time = convert_relative_time_to_iso(published_time_raw)\n",
    "\n",
    "\n",
    "            # Extract author name and designation\n",
    "            byline_block = article.find('div', {'data-component': 'byline-block'})\n",
    "            if byline_block:\n",
    "                author_name_tag = byline_block.find('span', class_='bZCrck')\n",
    "                if author_name_tag:\n",
    "                    author_name = author_name_tag.get_text()\n",
    "\n",
    "                author_designation_tag = byline_block.find('div', class_='hEbjLr')\n",
    "                if author_designation_tag:\n",
    "                    author_designation = author_designation_tag.get_text()\n",
    "\n",
    "                # Extract reporting location\n",
    "                reporting_location_tag = byline_block.find('span', string=lambda x: x and \"Reporting from\" in x)\n",
    "                if reporting_location_tag:\n",
    "                    reporting_location = reporting_location_tag.get_text().replace(\"Reporting from\", \"\").strip()\n",
    "        \n",
    "        # Extract images within <figure> tags\n",
    "        figures = soup.find_all('figure')\n",
    "        for fig in figures:\n",
    "            img = fig.find('img')\n",
    "            if img and img.get('src'):\n",
    "                # Some images might have relative URLs\n",
    "                img_url = img['src']\n",
    "                if img_url.startswith('//'):\n",
    "                    img_url = 'https:' + img_url\n",
    "                elif img_url.startswith('/'):\n",
    "                    img_url = 'https://www.bbc.com' + img_url\n",
    "                images.append(img_url)\n",
    "        \n",
    "        return {\n",
    "            \"description\": full_text if full_text else \"Full content not available\",\n",
    "            \"published_time\": published_time,\n",
    "            \"author_name\": author_name,\n",
    "            \"author_designation\": author_designation,\n",
    "            \"reporting_location\": reporting_location,\n",
    "            \"images\": images\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch full content from {url}: {e}\")\n",
    "        return {\n",
    "            \"description\": \"Failed to fetch full content\",\n",
    "            \"published_time\": \"\",\n",
    "            \"author_name\": \"\",\n",
    "            \"author_designation\": \"\",\n",
    "            \"reporting_location\": \"\",\n",
    "            \"images\": []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1e0c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_duplicate_article(new_article, existing_articles):\n",
    "    \"\"\"\n",
    "    Check if the new article is a duplicate based on title similarity and source.\n",
    "    If the title matches exactly and the source is the same, it's considered a duplicate.\n",
    "    \"\"\"\n",
    "    for article_item in existing_articles:\n",
    "        # Ensure the existing article has a title and source\n",
    "        if 'title' in article_item and 'source' in article_item:\n",
    "            if article_item['title_or'] == new_article['title_or'] and article_item['source'] == new_article['source']:\n",
    "                print(f\"Duplicate title found in the same source: {article_item['title_or']} (Source: {article_item['source']})\")\n",
    "                return True\n",
    "        else:\n",
    "            # If either title or source is missing, we can't reliably check for duplicates\n",
    "            continue\n",
    "            \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30c9a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_category(article_content):\n",
    "    \"\"\"\n",
    "    Determines the category of the article based on its content.\n",
    "    \"\"\"\n",
    "    # Define keywords for each category\n",
    "    categories = {\n",
    "        #\"Breaking\": [\"breaking\", \"urgent\", \"just in\"],\n",
    "        \"World\": [\"government\", \"policy\", \"election\", \"political\", \"politics\", \"weather\", \"storm\", \"temperature\", \"forecast\", \"climate\", \"environment\", \"sustainability\", \"nature\"],\n",
    "        \"Business\": [\"business\", \"market\", \"stocks\", \"finance\", \"economy\"],\n",
    "        \"Technology\": [\"research\", \"scientists\", \"study\", \"laboratory\", \"experiment\", \"science\"],\n",
    "        \"Sports\": [\"game\", \"match\", \"tournament\", \"league\", \"athlete\"],\n",
    "        #\"Art & Culture\": [\"art\", \"museum\", \"culture\", \"festival\", \"heritage\"],\n",
    "        \"Entertainment\": [\"celebrity\", \"movie\", \"music\", \"show\", \"award\", \"art\", \"museum\", \"culture\", \"festival\", \"heritage\", \"travel\", \"tourism\", \"destination\", \"flight\", \"hotel\"],\n",
    "        #\"Travel\": [\"travel\", \"tourism\", \"destination\", \"flight\", \"hotel\"],\n",
    "        #\"Weather\": [\"weather\", \"storm\", \"temperature\", \"forecast\"],\n",
    "        #\"Earth\": [\"climate\", \"environment\", \"sustainability\", \"nature\"],\n",
    "        #\"Local\": [\"local\", \"community\", \"neighborhood\", \"town\"]\n",
    "    }\n",
    "\n",
    "    # Default category\n",
    "    assigned_category = \"World\"\n",
    "\n",
    "    # Check for category keywords\n",
    "    for category, keywords in categories.items():\n",
    "        if any(keyword in article_content.lower() for keyword in keywords):\n",
    "            assigned_category = category\n",
    "            break\n",
    "    print(f\"Assigned category: {assigned_category}\")\n",
    "    return assigned_category\n",
    "\n",
    "# Example usage with an article\n",
    "#article_content = \"\"\"The government has announced a new policy that will affect the election process.\"\"\"\n",
    "#category = determine_category(article_content)\n",
    "#print(f\"Assigned category: {category}\")  # Should print \"Politics\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06b8379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_articles_to_mongo(articles):\n",
    "    \"\"\"Save articles to MongoDB, avoiding duplicates based on title similarity across sources.\"\"\"\n",
    "    # Fetch all existing articles from the database for comparison\n",
    "    existing_articles = list(collection.find({}, {'title_or': 1}))  # Only fetch titles for comparison\n",
    "\n",
    "    for article in articles:\n",
    "        # Check for duplicate articles based on title similarity\n",
    "        if not is_duplicate_article(article, existing_articles):\n",
    "            collection.insert_one(article)\n",
    "            print(f\"Saved article: {article['title_or']}\")\n",
    "        else:\n",
    "            print(f\"Duplicate article skipped: {article['title_or']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78649a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rss_feed(rss_url, driver, portal):\n",
    "    feed = feedparser.parse(rss_url)\n",
    "    title = \"\"\n",
    "    description = \"\"\n",
    "    news_data = []\n",
    "    images = []\n",
    "    \n",
    "    # Fetch existing titles from MongoDB for duplicate checking\n",
    "    existing_titles = list(collection.find({}, {'title_or': 1}))\n",
    "    #print(f\"Skipping duplicate titles: {existing_titles}\")\n",
    "    existing_titles = [item['title_or'] for item in existing_titles]\n",
    "\n",
    "    for entry in feed.entries:\n",
    "        title = entry.title\n",
    "        \n",
    "        url = entry.link\n",
    "        article_details = ''\n",
    "\n",
    "        # Check for duplicates\n",
    "        if is_duplicate_article({\"title_or\": title}, existing_titles):\n",
    "            print(f\"Duplicate article skipped: {title}\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        print(f\"Portal: {portal}\")\n",
    "\n",
    "        # Fetch additional details from the article page\n",
    "        article_details = fetch_full_article_bbc(url, driver)\n",
    "        \n",
    "        if article_details.get(\"description\", \"\") != \"\":\n",
    "            description = article_details.get(\"description\", \"\")            \n",
    "            category = determine_category(description)\n",
    "            print(f\"Title: {title}\")  # Should print the Title\n",
    "            images = article_details.get(\"images\", [])\n",
    "        \n",
    "            # Use .get() to avoid KeyError for missing fields\n",
    "            news_item = {            \n",
    "                \"title_or\": title,\n",
    "                \"description_or\": description,\n",
    "                \"url\": url,\n",
    "                \"published_time\": article_details.get(\"published_time\", \"\"),\n",
    "                \"author_name\": article_details.get(\"author_name\", \"\"),\n",
    "                \"author_designation\": article_details.get(\"author_designation\", \"\"),  # Optional field\n",
    "                \"reporting_location\": article_details.get(\"reporting_location\", \"\"),  # Optional field\n",
    "                \"images\": images,  # Optional field, default to empty list\n",
    "                \"source\": portal,\n",
    "                \"category\": category, \n",
    "                \"like\": 0,\n",
    "                \"comment\": 0,\n",
    "                \"share\": 0,\n",
    "                \"follow\": 0,\n",
    "                \"processed\": 0,\n",
    "                \"fetched_at\": datetime.now()\n",
    "            }\n",
    "            #print(news_item)  # Print news details to the console\n",
    "            news_data.append(news_item)\n",
    "    \n",
    "    return news_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "523e5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_news():\n",
    "    \"\"\"Crawl all news outlets and save to MongoDB\"\"\"    \n",
    "    driver = setup_driver()\n",
    "    rss_url = \"http://feeds.bbci.co.uk/news/rss.xml\"\n",
    "    print(rss_url);\n",
    "    try:\n",
    "        # Handle other portals with single URL feeds\n",
    "        news_data = parse_rss_feed(rss_url, driver, 'bbc')\n",
    "        save_articles_to_mongo(news_data)\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e953b1-6e5d-49bb-9929-7d9d32702c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34859af-56ce-41ed-83fc-41fb0482ab21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c72c48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://feeds.bbci.co.uk/news/rss.xml\n",
      "Portal: bbc\n",
      "Time: 5 hours ago\n",
      "Assigned category: World\n",
      "Title: Calls for Archbishop of York to resign over Church failings in sex abuse case\n",
      "Portal: bbc\n",
      "Time: 3 hours ago\n",
      "Assigned category: World\n",
      "Title: Councils to be merged in major local government shake-up\n",
      "Portal: bbc\n",
      "Time: 10 hours ago\n",
      "Assigned category: World\n",
      "Title: Why are more parents home-educating their children?\n",
      "Portal: bbc\n",
      "Time: 24 minutes ago\n",
      "Assigned category: World\n",
      "Title: China's efforts to spy in the UK happening in plain view, says ex-Tory leader\n",
      "Portal: bbc\n",
      "Time: 4 hours ago\n",
      "Assigned category: Entertainment\n",
      "Title: Tourists in Fiji ill after suspected pina-colada poisoning\n",
      "Portal: bbc\n",
      "Time: 1 hour ago\n",
      "Assigned category: World\n",
      "Title: Woman killed in London triple shooting named\n",
      "Portal: bbc\n",
      "Time: 1 hour ago\n",
      "Assigned category: World\n",
      "Title: Royal Mail takeover by Czech billionaire approved\n",
      "Portal: bbc\n",
      "Time: 1 hour ago\n",
      "Assigned category: Entertainment\n",
      "Title: Twelve dead from carbon monoxide poisoning at Georgia ski resort\n",
      "Portal: bbc\n",
      "Time: 20 minutes ago\n",
      "Assigned category: World\n",
      "Title: Woman sentenced for hurling milkshake at Farage\n",
      "Portal: bbc\n",
      "Time: 10 hours ago\n",
      "Assigned category: Entertainment\n",
      "Title: Robbie Williams on why he's played by a chimp in new film\n",
      "Portal: bbc\n",
      "Time: 11 hours ago\n",
      "Assigned category: World\n",
      "Title: Scandinavian wine industry hoping to win over drinkers\n",
      "Portal: bbc\n",
      "Time: 5 hours ago\n",
      "Assigned category: Business\n",
      "Title: How families' bitter and bloody feud spilled onto Glasgow's streets\n",
      "Portal: bbc\n",
      "Time: 55 minutes ago\n",
      "Assigned category: World\n",
      "Title: Why Final Fantasy director almost rejected his dream job\n",
      "Portal: bbc\n",
      "Time: 1 day ago\n",
      "Assigned category: Business\n",
      "Title: Gisèle Pelicot removes all traces of her husband from her life\n",
      "Portal: bbc\n",
      "Time: 13 hours ago\n",
      "Assigned category: World\n",
      "Title: 'We just need peace': BBC speaks to Syrians watching Israel's incursion\n",
      "Portal: bbc\n",
      "Time: 11 hours ago\n",
      "Assigned category: World\n",
      "Title: Why a nation of 1.45 billion wants more children\n",
      "Portal: bbc\n",
      "Time: 20 August\n",
      "Assigned category: World\n",
      "Title: BBC News app\n",
      "Portal: bbc\n",
      "Time: 1 hour ago\n",
      "Assigned category: World\n",
      "Title: Turkey and sprouts drives down cost of Christmas dinner\n",
      "Portal: bbc\n",
      "Assigned category: World\n",
      "Title: BBC presenter revisits 'mortifying' blunder that went viral\n",
      "Portal: bbc\n",
      "Time: 23 minutes ago\n",
      "Assigned category: Entertainment\n",
      "Title: Girl, 12, charged with manslaughter of 80-year-old\n",
      "Portal: bbc\n",
      "Time: 5 hours ago\n",
      "Assigned category: World\n",
      "Title: 'Our rapists should admit guilt before they get parole'\n",
      "Portal: bbc\n",
      "Time: 11 hours ago\n",
      "Assigned category: World\n",
      "Title: Bronze Age massacre victims likely cannibalised\n",
      "Portal: bbc\n",
      "Time: 1 hour ago\n",
      "Assigned category: World\n",
      "Title: Social media given 'last chance' to tackle illegal posts\n",
      "Portal: bbc\n",
      "Time: 3 hours ago\n",
      "Assigned category: Sports\n",
      "Title: Commentator Isa Guha sorry for calling cricketer 'primate'\n",
      "Portal: bbc\n",
      "Assigned category: World\n",
      "Title: Migration, Migration, Migration\n",
      "Portal: bbc\n",
      "Assigned category: World\n",
      "Title: Why is the internet obsessed with a suspected CEO killer?\n",
      "Portal: bbc\n",
      "Time: 16 December 2024, 06:29 GMT\n",
      "Assigned category: World\n",
      "Title: Stokes blow compounds England slide towards defeat\n",
      "Portal: bbc\n",
      "Time: 4 hours ago\n",
      "Assigned category: Entertainment\n",
      "Title: Cavendish wins BBC Lifetime Achievement award\n",
      "Portal: bbc\n",
      "Time: 15 December 2024\n",
      "Assigned category: Sports\n",
      "Title: Southampton sack manager Martin after Spurs thrashing\n",
      "Portal: bbc\n",
      "Time: 15 December 2024\n",
      "Assigned category: Business\n",
      "Title: 'I am not good enough' - Guardiola faces daunting and major rebuild\n",
      "Portal: bbc\n",
      "Time: 15 December 2024\n",
      "Assigned category: Sports\n",
      "Title: Six goals, 10 pens & 120 minutes of Old Firm chaos\n",
      "Saved article: Calls for Archbishop of York to resign over Church failings in sex abuse case\n",
      "Saved article: Councils to be merged in major local government shake-up\n",
      "Saved article: Why are more parents home-educating their children?\n",
      "Saved article: China's efforts to spy in the UK happening in plain view, says ex-Tory leader\n",
      "Saved article: Tourists in Fiji ill after suspected pina-colada poisoning\n",
      "Saved article: Woman killed in London triple shooting named\n",
      "Saved article: Royal Mail takeover by Czech billionaire approved\n",
      "Saved article: Twelve dead from carbon monoxide poisoning at Georgia ski resort\n",
      "Saved article: Woman sentenced for hurling milkshake at Farage\n",
      "Saved article: Robbie Williams on why he's played by a chimp in new film\n",
      "Saved article: Scandinavian wine industry hoping to win over drinkers\n",
      "Saved article: How families' bitter and bloody feud spilled onto Glasgow's streets\n",
      "Saved article: Why Final Fantasy director almost rejected his dream job\n",
      "Saved article: Gisèle Pelicot removes all traces of her husband from her life\n",
      "Saved article: 'We just need peace': BBC speaks to Syrians watching Israel's incursion\n",
      "Saved article: Why a nation of 1.45 billion wants more children\n",
      "Saved article: BBC News app\n",
      "Saved article: Turkey and sprouts drives down cost of Christmas dinner\n",
      "Saved article: BBC presenter revisits 'mortifying' blunder that went viral\n",
      "Saved article: Girl, 12, charged with manslaughter of 80-year-old\n",
      "Saved article: 'Our rapists should admit guilt before they get parole'\n",
      "Saved article: Bronze Age massacre victims likely cannibalised\n",
      "Saved article: Social media given 'last chance' to tackle illegal posts\n",
      "Saved article: Commentator Isa Guha sorry for calling cricketer 'primate'\n",
      "Saved article: Migration, Migration, Migration\n",
      "Saved article: Why is the internet obsessed with a suspected CEO killer?\n",
      "Saved article: Stokes blow compounds England slide towards defeat\n",
      "Saved article: Cavendish wins BBC Lifetime Achievement award\n",
      "Saved article: Southampton sack manager Martin after Spurs thrashing\n",
      "Saved article: 'I am not good enough' - Guardiola faces daunting and major rebuild\n",
      "Saved article: Six goals, 10 pens & 120 minutes of Old Firm chaos\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    crawl_news()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
